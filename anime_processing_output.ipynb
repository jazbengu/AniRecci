{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6121d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "user_anime_titles = \"[\\\"Boku no Hero Academia\\\"]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5b5b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gjw2IyhVFr5F",
    "outputId": "b355f820-bc67-4810-8e84-b38f77efd490",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install requests pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720849e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5diRPWlFVDH",
    "outputId": "fe1c0677-c83c-46fd-b3ba-cbc8c7b270d6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch anime data with pagination\n",
    "def fetch_anime_data_paged(limit=4500):\n",
    "    anime_list = []\n",
    "    current_page = 1\n",
    "    fetched_count = 0\n",
    "\n",
    "    while fetched_count < limit:\n",
    "        try:\n",
    "            url = f\"https://api.jikan.moe/v4/anime?page={current_page}\"\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json().get('data', [])\n",
    "                if not data:\n",
    "                    print(\"No more anime data available.\")\n",
    "                    break\n",
    "\n",
    "                for anime in data:\n",
    "                    anime_data = {\n",
    "                        'id': anime.get('mal_id'),\n",
    "                        'title': anime.get('title'),\n",
    "                        'genres': [genre['name'] for genre in anime.get('genres', [])],\n",
    "                        'popularity': anime.get('popularity'),\n",
    "                        'rating': anime.get('score'),\n",
    "                        'description': anime.get('synopsis'),\n",
    "                    }\n",
    "                    anime_list.append(anime_data)\n",
    "                    fetched_count += 1\n",
    "                    if fetched_count >= limit:\n",
    "                        break\n",
    "\n",
    "                current_page += 1\n",
    "            else:\n",
    "                print(f\"Error fetching page {current_page}: HTTP {response.status_code}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page {current_page}: {e}\")\n",
    "            break\n",
    "\n",
    "    return anime_list\n",
    "\n",
    "anime_data = fetch_anime_data_paged(limit=4500)\n",
    "\n",
    "anime_df = pd.DataFrame(anime_data)\n",
    "\n",
    "anime_df.to_csv('raw_anime_data_paged.csv', index=False)\n",
    "print(\"Anime data saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998a5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JIHIuN5Jnsu",
    "outputId": "b597d139-ebaa-41df-9c8d-39a7bc41da4c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(anime_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2b6e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32LhF31RID2e",
    "outputId": "2dd77347-2034-43b7-acd4-0ade14955afd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "anime_df = pd.read_csv('raw_anime_data_paged.csv')\n",
    "anime_df = anime_df.drop_duplicates(subset='title', keep='first')\n",
    "anime_df['rating'] = anime_df['rating'].fillna(anime_df['rating'].mean())\n",
    "anime_df['description'] = anime_df['description'].fillna(\"No description available.\")\n",
    "anime_df['genres'] = anime_df['genres'].apply(lambda x: [g.lower() for g in eval(x)] if pd.notna(x) else [])\n",
    "anime_df['popularity'] = anime_df['popularity'].fillna(anime_df['popularity'].max())\n",
    "threshold = anime_df[\"popularity\"].quantile(0.5)\n",
    "\n",
    "# Filter less popular anime\n",
    "less_popular_anime = anime_df[anime_df[\"popularity\"] > threshold]\n",
    "\n",
    "# Save the filtered dataset if needed\n",
    "less_popular_anime.to_csv('less_popular_anime.csv', index=False)\n",
    "print(\"Filtered less popular anime saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99361f7a",
   "metadata": {
    "id": "W1D0arssI8TS",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d57150",
   "metadata": {
    "id": "U8w59iUCI4A2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF for descriptions\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(anime_df['description'])\n",
    "\n",
    "# Compute similarity\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff6ca1",
   "metadata": {
    "collapsed": true,
    "id": "D-G83bwsK0zL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch anime details function\n",
    "def fetch_anime_details(title):\n",
    "    try:\n",
    "        url = f\"https://api.jikan.moe/v4/anime?q={title}&limit=1\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get('data', [])\n",
    "            if data:\n",
    "                anime = data[0]\n",
    "                return {\n",
    "                    'id': anime.get('mal_id'),\n",
    "                    'title': anime.get('title'),\n",
    "                    'genres': [genre['name'] for genre in anime.get('genres', [])],\n",
    "                    'description': anime.get('synopsis', \"\"),\n",
    "                    'rating': anime.get('score', 0)\n",
    "                }\n",
    "        else:\n",
    "            print(f\"Error fetching details for '{title}': HTTP {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for '{title}': {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0110d7",
   "metadata": {
    "id": "vCrWKkFuK85g",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommendation function with error handling and filtering of indices\n",
    "def recommend_less_popular(fetched_anime, num_recommendations=5):\n",
    "    # Add fetched anime descriptions to the TF-IDF vector space\n",
    "    fetched_descriptions = [anime['description'] for anime in fetched_anime if anime]\n",
    "\n",
    "    if not fetched_descriptions:\n",
    "        print(\"No valid descriptions available for recommendations.\")\n",
    "        return []\n",
    "\n",
    "    fetched_features = tfidf.transform(fetched_descriptions).mean(axis=0).A1\n",
    "    similarity_scores = cosine_similarity(fetched_features.reshape(1, -1), tfidf_matrix)\n",
    "\n",
    "    # Rank less popular anime by similarity\n",
    "    scores = [(i, similarity_scores[0, i]) for i in range(len(similarity_scores[0])) if i < len(less_popular_anime)]\n",
    "\n",
    "    # Debugging: Print the filtered scores\n",
    "    print(\"Filtered Scores (valid indices only):\", scores)\n",
    "\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Check if there are enough recommendations available\n",
    "    if len(scores) < num_recommendations:\n",
    "        print(f\"Only {len(scores)} less popular anime found for recommendations.\")\n",
    "        num_recommendations = len(scores)\n",
    "\n",
    "    # Return top recommendations\n",
    "    recommendations = []\n",
    "    for i in scores[:num_recommendations]:\n",
    "        try:\n",
    "            recommendations.append(less_popular_anime.iloc[i[0]]['title'])\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError while accessing less_popular_anime: {e}\")\n",
    "            print(f\"Current index being accessed: {i[0]}\")\n",
    "            continue  # Skip this index if there's an error\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616d0df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "W5YHhTVdQ6ao",
    "outputId": "68ac6135-9aa0-448c-e658-bb326da0ffb2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    import json\n",
    "\n",
    "    # Read the input titles from the parameters\n",
    "    user_anime_titles = json.loads(sys.argv[1])  # Expecting a JSON string\n",
    "\n",
    "    fetched_anime = []\n",
    "    for title in user_anime_titles:\n",
    "        title = title.strip()\n",
    "        anime_details = fetch_anime_details(title)\n",
    "        if anime_details:\n",
    "            fetched_anime.append(anime_details)\n",
    "\n",
    "    # Generate recommendations\n",
    "    recommendations = []\n",
    "    if fetched_anime:\n",
    "        recommendations = recommend_less_popular(fetched_anime, num_recommendations=5)\n",
    "\n",
    "    # Save recommendations to a CSV file\n",
    "    recommendations_df = pd.DataFrame(recommendations, columns=[\"Recommended Titles\"])\n",
    "    recommendations_df.to_csv('anime_recommendations.csv', index=False)\n",
    "\n",
    "    print(\"Recommendations saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.004352,
   "end_time": "2024-11-19T19:18:47.214693",
   "environment_variables": {},
   "exception": null,
   "input_path": "anime_processing.ipynb",
   "output_path": "anime_processing_output.ipynb",
   "parameters": {
    "user_anime_titles": "[\"Boku no Hero Academia\"]"
   },
   "start_time": "2024-11-19T19:18:47.210341",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}